{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports all necessary libraries and defines some global constants.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# each image dimension is (128, 384). After segmentation the following will be the dimensions of each character.\n",
    "charHeight = 128\n",
    "charWidth = 128\n",
    "numImages = 48574\n",
    "\n",
    "vectorLength = 16384\n",
    "\n",
    "imgPath = \"SoML-50/SoML-50/data/\"\n",
    "csvPath = \"SoML-50/SoML-50/annotations.csv\"\n",
    "\n",
    "def getPathOfImg (index):\n",
    "    return (imgPath + str (index) + \".jpg\")\n",
    "\n",
    "def getLabelOfImg (df,index):\n",
    "    return (df.loc[df['Image'] == (str(index) + '.jpg')]['Label'].values[0])\n",
    "\n",
    "def getValueOfImg (df, index):\n",
    "    return (int(df.loc[df['Image'] == (str(index) + '.jpg')]['Value'].values[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we divide the data set into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "imgIndex = [ i for i in range (1, numImages+1)]\n",
    "train_set, test_set = train_test_split (imgIndex, test_size= 0.1, random_state= 1)\n",
    "\n",
    "df = pd.read_csv (csvPath)\n",
    "\n",
    "print (getLabelOfImg (df,5))\n",
    "print (getValueOfImg (df,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell takes the image number and returns the numpy array of length 3 - Ready for applying K-means clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 16384)\n"
     ]
    }
   ],
   "source": [
    "def vectoriseImg (image):\n",
    "    return np.reshape (image, (1,-1))\n",
    "\n",
    "def getSegmentedVectors (df,index):\n",
    "    \"\"\" This function returns a numpy array of the three character images of shape (128,128) present in index.jpg after converting them into vectors \n",
    "    as required by K-Means algorithm. You cannot directly apply K-Means to image Matrices. First need to vectorise image matrix. \n",
    "    Also, the operator is always present at [0] and other two operands at [1] and [2] in the order in which the operator has to be applied.\"\"\"\n",
    "    \n",
    "    image = imread (getPathOfImg(index))\n",
    "    label = getLabelOfImg (df, index)\n",
    "    if (label == 'prefix'):\n",
    "        charArray = np.array ([image[:, 0:charWidth],image[:, charWidth:(2*charWidth)],image[:, (2*charWidth):]])\n",
    "    elif (label == 'postfix'):\n",
    "        charArray = np.array ([image[:, (2*charWidth):],image[:, 0:charWidth],image[:, charWidth:(2*charWidth)]])\n",
    "    else:\n",
    "        charArray = np.array ([image[:, charWidth:(2*charWidth)],image[:, 0:charWidth],image[:, (2*charWidth):]])\n",
    "    \n",
    "    ans = np.array ([vectoriseImg (charArray[i]) for i in range (3)])\n",
    "    return ans\n",
    "\n",
    "print ((getSegmentedVectors (df, 6).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create numpy matrices on which KMeans class object will cluster the rows. We create three numpy arrays, each for the two operand vectors and one for the operator vector. \n",
    "\n",
    "Note that we initialize the arrays with the required shape at the beginning itself. We should not do append to numpy arrays as they are stored in contiguous blocks of memory and whole array needs to be copied again and again in order to append. Source: https://stackoverflow.com/questions/568962/how-do-i-create-an-empty-array-matrix-in-numpy\n",
    "\n",
    "I faced with a problem here - I cannot initialize 3 arrays as big as len(train_set) * vectorLength = ~ 45000 * 16000 =~ 10^9. My entire 16 GB ram was not enough and the laptop kept on freezing. Hence I chose the mini batch training which took mini batches of size 10 images at a time and trained the k means clustering model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our matrices on which mini batch KMeans clustering will work are declared. \n",
    "operators = np.empty (shape = [10, vectorLength], dtype = int)\n",
    "operands = np.empty (shape = [20, vectorLength], dtype = int)\n",
    "\n",
    "\n",
    "# now initialize KMeans class object. \n",
    "operatorCluster = MiniBatchKMeans( n_clusters = 4, random_state=0, batch_size = 10)\n",
    "operandCluster = MiniBatchKMeans( n_clusters= 10, random_state=0, batch_size = 20)\n",
    "\n",
    "for i in range (1,len(train_set)-10, 10):\n",
    "    for j in range (i,i+10):\n",
    "        segments = getSegmentedVectors (df, train_set[j])\n",
    "        operators[j-i] , operands[j-i], operands[j-i + 10] = segments[0] , segments[1] , segments[2]\n",
    "    operatorCluster = operatorCluster.partial_fit(operators)\n",
    "    operandCluster = operandCluster.partial_fit(operands)\n",
    "    \n",
    "# now our we have trained our clustering model. This cell took approximately 190 seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.985780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.079506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "count  50000.000000\n",
       "mean       8.985780\n",
       "std       14.079506\n",
       "min       -9.000000\n",
       "25%        0.000000\n",
       "50%        5.000000\n",
       "75%       12.000000\n",
       "max       81.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = df.sort_values (by = ['Value'])\n",
    "#print (sorted_df.tail (20))\n",
    "sorted_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73bd737fbce9fefea06c333d19b0e4dd23dd32e9701a28ba35ccf8a2425e105d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('my_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}