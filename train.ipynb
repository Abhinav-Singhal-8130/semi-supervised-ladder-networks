{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports all necessary libraries and defines some global constants.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# each image dimension is (128, 384). After segmentation the following will be the dimensions of each character.\n",
    "charHeight = 128\n",
    "charWidth = 128\n",
    "numImages = 50000\n",
    "\n",
    "vectorLength = 16384\n",
    "\n",
    "imgPath = \"SoML-50/SoML-50/data/\"\n",
    "csvPath = \"SoML-50/SoML-50/annotations.csv\"\n",
    "\n",
    "def getPathOfImg (index):\n",
    "    return (imgPath + str (index) + \".jpg\")\n",
    "\n",
    "def getLabelOfImg (df,index):\n",
    "    return (df.loc[df['Image'] == (str(index) + '.jpg')]['Label'].values[0])\n",
    "\n",
    "def getValueOfImg (df, index):\n",
    "    return (int(df.loc[df['Image'] == (str(index) + '.jpg')]['Value'].values[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we divide the data set into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv (csvPath)\n",
    "\n",
    "print (getLabelOfImg (df,5))\n",
    "print (getValueOfImg (df,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell takes the image number and returns the numpy array of length 3 - Ready for applying K-means clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 16384)\n"
     ]
    }
   ],
   "source": [
    "def vectoriseImg (image):\n",
    "    return np.reshape (image, (1,-1))\n",
    "\n",
    "def getSegmentedVectors (df,index):\n",
    "    \"\"\" This function returns a numpy array of the three character images of shape (128,128) present in index.jpg after converting them into vectors \n",
    "    as required by K-Means algorithm. You cannot directly apply K-Means to image Matrices. First need to vectorise image matrix. \n",
    "    Also, the operator is always present at [0] and other two operands at [1] and [2] in the order in which the operator has to be applied.\"\"\"\n",
    "    \n",
    "    image = imread (getPathOfImg(index))\n",
    "    label = getLabelOfImg (df, index)\n",
    "    if (label == 'prefix'):\n",
    "        charArray = np.array ([image[:, 0:charWidth],image[:, charWidth:(2*charWidth)],image[:, (2*charWidth):]])\n",
    "    elif (label == 'postfix'):\n",
    "        charArray = np.array ([image[:, (2*charWidth):],image[:, 0:charWidth],image[:, charWidth:(2*charWidth)]])\n",
    "    else:\n",
    "        charArray = np.array ([image[:, charWidth:(2*charWidth)],image[:, 0:charWidth],image[:, (2*charWidth):]])\n",
    "\n",
    "    ans = np.array ([vectoriseImg (charArray[i]) for i in range (3)])\n",
    "    return ans\n",
    "\n",
    "print ((getSegmentedVectors (df, 6).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create numpy matrices on which KMeans class object will cluster the rows. We create two numpy arrays, one for the operand vectors and one for the operator vectors. \n",
    "\n",
    "Note that we initialize the arrays with the required shape at the beginning itself. We should not do append to numpy arrays as they are stored in contiguous blocks of memory and whole array needs to be copied again and again in order to append. Source: https://stackoverflow.com/questions/568962/how-do-i-create-an-empty-array-matrix-in-numpy\n",
    "\n",
    "I faced with a problem here - I cannot initialize 2 arrays as big as len(train_set) * vectorLength = ~ 45000 * 16000 =~ 10^9. My entire 16 GB ram was not enough and the laptop kept on freezing. Hence I chose the mini batch training which took mini batches of size 10 images at a time and trained the k means clustering model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our matrices on which mini batch KMeans clustering will work are declared. \n",
    "operators = np.empty (shape = [100, vectorLength], dtype = int)\n",
    "operands = np.empty (shape = [200, vectorLength], dtype = int)\n",
    "\n",
    "# now initialize KMeans class object. \n",
    "operatorCluster = MiniBatchKMeans(n_clusters = 4, random_state=0, batch_size = 100)\n",
    "operandCluster = MiniBatchKMeans(n_clusters = 10, random_state=0, batch_size = 200)\n",
    "\n",
    "for i in range (1,len(train_set)-100, 100):\n",
    "    for j in range (i,i+100):\n",
    "        segments = getSegmentedVectors (df, train_set[j])\n",
    "        operators[j-i] , operands[j-i],operands[j-i + 100] = segments[0],segments[1],segments[2]\n",
    "    operatorCluster = operatorCluster.partial_fit(operators)\n",
    "    operandCluster = operandCluster.partial_fit(operands)\n",
    "    \n",
    "# now our we have trained our clustering model. This cell took approximately 190 seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.985780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.079506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value\n",
       "count  50000.000000\n",
       "mean       8.985780\n",
       "std       14.079506\n",
       "min       -9.000000\n",
       "25%        0.000000\n",
       "50%        5.000000\n",
       "75%       12.000000\n",
       "max       81.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = df.sort_values (by = ['Value'])\n",
    "#print (sorted_df.head(5))\n",
    "\n",
    "sorted_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now first filter out all values which are negative. mark the cluster which has maximum of those operators as a subtraction symbol\n",
    "\n",
    "-9 : 0 and 9 confirmed and - symbol confirmed\n",
    "81 : 9 and * confirmed\n",
    "above 18: multiply confirmed :\n",
    "\n",
    "1 * 1 = 1\n",
    "numbers predicted - 0, 1, 5, 7, 8, 9\n",
    "25  \n",
    "49\n",
    "64\n",
    "81\n",
    "\n",
    "30 : 5 * 6  (6 predicted)\n",
    "32 : 4 * 8 (4 predicted)\n",
    "54 : 4 * 9 (4 predicted)\n",
    "14 : 7 * 2 (2 predicted)\n",
    "\n",
    "numbers remaining : 3\n",
    "\n",
    "\n",
    "\n",
    "11\n",
    "13\n",
    "17\n",
    "\n",
    "\n",
    "\n",
    "# Then, filter out all operator vectors for which image has value above 18. mark the cluster which has maximum of those operators as a multiplication symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4820, 5315, 25910, 13955]\n"
     ]
    }
   ],
   "source": [
    "# test_df = sorted_df.apply (lambda x : True if x['Value'] > 18 else False, axis = 1)\n",
    "# print (test_df[sorted_df['Value'] > 18])\n",
    "def getIndex(ss): \n",
    "    return int (ss[:-4])\n",
    "\n",
    "count = [0,0,0,0]\n",
    "for index, row in sorted_df.iterrows():     \n",
    "    #if (row['Value'] > 18): \n",
    "    imgIndex = getIndex(row['Image']) \n",
    "    segments = getSegmentedVectors (df,imgIndex)\n",
    "    count[operatorCluster.predict (segments[0])[0]] += 1\n",
    "\n",
    "print (count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[4820, 5315, 25910, 13955]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6150\n"
     ]
    }
   ],
   "source": [
    "num11 = df.apply(lambda x : True\n",
    "            if x['Value'] == 11 else False, axis = 1)\n",
    "num11 = len(df[num11 == True].index)\n",
    "\n",
    "num17 = df.apply(lambda x : True\n",
    "            if x['Value'] == 17 else False, axis = 1)\n",
    "num17 = len(df[num17 == True].index)\n",
    "\n",
    "num13 = df.apply(lambda x : True\n",
    "            if x['Value'] == 13 else False, axis = 1)\n",
    "num13 = len(df[num13 == True].index)\n",
    "\n",
    "numNeg = df.apply(lambda x : True\n",
    "            if x['Value'] > 18 else False, axis = 1)\n",
    "numNeg = len(df[numNeg == True].index)\n",
    "\n",
    "print (numNeg)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73bd737fbce9fefea06c333d19b0e4dd23dd32e9701a28ba35ccf8a2425e105d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('my_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}